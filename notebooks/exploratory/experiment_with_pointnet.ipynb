{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from torchmetrics.classification import MulticlassMatthewsCorrCoef\n",
    "import open3d as o3\n",
    "# from open3d import JVisualizer # For Colab Visualization\n",
    "# from open3d.web_visualizer import draw # for non Colab\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "# dataset\n",
    "# ROOT = r'C:\\Users\\itber\\Documents\\datasets\\S3DIS\\Stanford3dDataset_v1.2_Reduced_Parti\\tioned_Aligned_Version_1m'\n",
    "\n",
    "root = \"E:\\\\Nick\\\\Cole Trapnell's Lab Dropbox\\\\Nick Lammers\\\\Nick\\\\pecfin_dynamics\\\\fin_morphodynamics\\\\\"\n",
    "data_root = os.path.join(root, \"built_data\\\\point_clouds\\\\\")\n",
    "\n",
    "# feature selection hyperparameters\n",
    "NUM_TRAIN_POINTS = 4096 # train/valid points\n",
    "NUM_TEST_POINTS = 4096\n",
    "BATCH_SIZE = 16"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from fin_morphodynamics.src.functions.data_utilities import PointData\n",
    "\n",
    "# get datasets\n",
    "# point_data = PointData(ROOT, npoints=NUM_TRAIN_POINTS, r_prob=0.25)\n",
    "# valid_data = PointData(ROOT, npoints=NUM_TRAIN_POINTS, r_prob=0.)\n",
    "point_data = PointData(data_root, split='test', npoints=NUM_TEST_POINTS)\n",
    "\n",
    "# get dataloaders\n",
    "dataloader = DataLoader(point_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# valid_dataloader = DataLoader(s3dis_valid, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# test_dataloader = DataLoader(s3dis_test, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "from fin_morphodynamics.src.point_net.point_net import PointNetBackbone, PointNetSegHead\n",
    "\n",
    "code_root = \"C:\\\\Users\\\\nlammers\\\\Projects\\\\pecfin_dynamics\\\\fin_morphodynamics\\\\\"\n",
    "model_path = os.path.join(code_root, \"src\\point_net\\\\trained_models\\\\seg_focal\\seg_model_60.pth\")\n",
    "\n",
    "# point_mdl = torch.load(model_path)\n",
    "# point_mdl.eval()\n",
    "# point_mdl_bck = PointNetBackbone(local_feat=True, num_points=4096).eval()\n",
    "# point_mdl_bck.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# get intitial model architecture\n",
    "# model = PointNetSegHead(num_points=NUM_TRAIN_POINTS, m=NUM_CLASSES)\n",
    "NUM_CLASSES = 14\n",
    "\n",
    "model = PointNetSegHead(num_points=NUM_TEST_POINTS, m=NUM_CLASSES).to(DEVICE)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval();"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to some sample points and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "points, targets = next(iter(dataloader))\n",
    "points = torch.transpose(points, 1, 2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "points = points.to(DEVICE)\n",
    "pointfeat = model.backbone\n",
    "out, _, _ = pointfeat(points)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "import umap.umap_ as umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# initialize reducer\n",
    "n_components = 2\n",
    "reducer = umap.UMAP(n_components=n_components)\n",
    "\n",
    "        \n",
    "features = np.squeeze(out[0, :, :]).detach().cpu().T\n",
    "\n",
    "scaled_features = StandardScaler().fit_transform(features)\n",
    "embedding = reducer.fit_transform(scaled_features)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "points_cpu = np.squeeze(points[0, :, :].detach().cpu()).T\n",
    "fig = px.scatter_3d(x=points_cpu[:, 0], y=points_cpu[:, 1], z=-points_cpu[:, 2], color=embedding[:, 1])\n",
    "fig.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "features.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
