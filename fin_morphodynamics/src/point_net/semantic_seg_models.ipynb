{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Semantic Segmentation Models**\n",
    "\n",
    "In this notebook we will create a pipeline to perform semantic segmentation on point clouds of indoor spaces. This pipeline will incorporate a pretrained segmentation Point Net to get predictions for an input set of points. Then we will use open3d to search the point cloud space for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from torchmetrics.classification import MulticlassMatthewsCorrCoef\n",
    "import open3d as o3\n",
    "# from open3d import JVisualizer # For Colab Visualization\n",
    "from open3d.web_visualizer import draw # for non Colab\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP for supressing pytorch user warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\python.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Program Files (x86)/Microsoft Visual Studio/Shared/Python37_64/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "ROOT = r'C:\\Users\\itber\\Documents\\datasets\\S3DIS\\Stanford3dDataset_v1.2_Reduced_Partitioned_Aligned_Version_1m'\n",
    "\n",
    "# feature selection hyperparameters\n",
    "NUM_TRAIN_POINTS = 4096 # train/valid points\n",
    "NUM_TEST_POINTS = 15000\n",
    "\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = {\n",
    "    'ceiling'  : 0, \n",
    "    'floor'    : 1, \n",
    "    'wall'     : 2, \n",
    "    'beam'     : 3, \n",
    "    'column'   : 4, \n",
    "    'window'   : 5,\n",
    "    'door'     : 6, \n",
    "    'table'    : 7, \n",
    "    'chair'    : 8, \n",
    "    'sofa'     : 9, \n",
    "    'bookcase' : 10, \n",
    "    'board'    : 11,\n",
    "    'stairs'   : 12,\n",
    "    'clutter'  : 13\n",
    "}\n",
    "\n",
    "# unique color map generated via\n",
    "# https://mokole.com/palette.html\n",
    "COLOR_MAP = {\n",
    "    0  : (47, 79, 79),    # ceiling - darkslategray\n",
    "    1  : (139, 69, 19),   # floor - saddlebrown\n",
    "    2  : (34, 139, 34),   # wall - forestgreen\n",
    "    3  : (75, 0, 130),    # beam - indigo\n",
    "    4  : (255, 0, 0),     # column - red \n",
    "    5  : (255, 255, 0),   # window - yellow\n",
    "    6  : (0, 255, 0),     # door - lime\n",
    "    7  : (0, 255, 255),   # table - aqua\n",
    "    8  : (0, 0, 255),     # chair - blue\n",
    "    9  : (255, 0, 255),   # sofa - fuchsia\n",
    "    10 : (238, 232, 170), # bookcase - palegoldenrod\n",
    "    11 : (100, 149, 237), # board - cornflower\n",
    "    12 : (255, 105, 180), # stairs - hotpink\n",
    "    13 : (0, 0, 0)        # clutter - black\n",
    "}\n",
    "\n",
    "v_map_colors = np.vectorize(lambda x : COLOR_MAP[x])\n",
    "\n",
    "NUM_CLASSES = len(CATEGORIES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from s3dis_dataset import S3DIS\n",
    "\n",
    "# get datasets\n",
    "s3dis_test = S3DIS(ROOT, area_nums='6', split='test', npoints=NUM_TEST_POINTS)\n",
    "\n",
    "# get dataloaders\n",
    "test_dataloader = DataLoader(s3dis_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an example and display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points, targets = s3dis_test[10]\n",
    "\n",
    "pcd = o3.geometry.PointCloud()\n",
    "pcd.points = o3.utility.Vector3dVector(points)\n",
    "pcd.colors = o3.utility.Vector3dVector(np.vstack(v_map_colors(targets)).T/255)\n",
    "\n",
    "# draw(pcd)\n",
    "o3.visualization.draw_plotly([pcd])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Seg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from point_net import PointNetSegHead\n",
    "\n",
    "# get intitial model architecture\n",
    "# model = PointNetSegHead(num_points=NUM_TRAIN_POINTS, m=NUM_CLASSES)\n",
    "\n",
    "\n",
    "MODEL_PATH = 'trained_models/seg_focal/seg_model_60.pth'\n",
    "\n",
    "model = PointNetSegHead(num_points=NUM_TEST_POINTS, m=NUM_CLASSES).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection pipeline\n",
    "\n",
    "Now it's time to make the object detection pipeline. In appendix D of the Point Net paper, the authors choose a random point, find it's predicted class, then search for other predicted classes within a 0.2m radius, then if the resulting cluster contains more than 200 points, then the clusters bounding boxe is added to a list of proposals. We compute the average point score for each proposed object, by taking the total number of points assigned to the object divided by the total number of evaluated in the radius."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the searching with open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the points into an Nx3 array\n",
    "pcd_points = norm_points.permute(2, 0, 1).reshape(3, -1).to('cpu').T\n",
    "\n",
    "# place them into a point cloud object\n",
    "pcd = o3.geometry.PointCloud()\n",
    "pcd.points = o3.utility.Vector3dVector(pcd_points)\n",
    "\n",
    "# initialize KD tree object\n",
    "pcd_tree = o3.geometry.KDTreeFlann(pcd)\n",
    "\n",
    "# perform search over radius r = 0.2\n",
    "[k, idx, a] = pcd_tree.search_radius_vector_3d(pcd.points[1500], 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_downsample_choices(points, npoints):\n",
    "    if len(points) > npoints:\n",
    "        choice = np.random.choice(len(points), npoints, replace=False)\n",
    "    else:\n",
    "        choice = np.random.choice(len(points), npoints, replace=True)\n",
    "\n",
    "    return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pred_choice.reshape(-1).to('cpu') # Nx1\n",
    "pcd_points = norm_points.permute(2, 0, 1).reshape(3, -1).to('cpu').T # Nx3\n",
    "\n",
    "# downsample points\n",
    "choice = get_downsample_choices(pcd_points, 1500)\n",
    "pcd_points = pcd_points[choice]\n",
    "predictions = predictions[choice]\n",
    "\n",
    "# only obtain points for current category\n",
    "pcd_points = pcd_points[predictions == 0, :]\n",
    "\n",
    "# place them into a point cloud object\n",
    "pcd = o3.geometry.PointCloud()\n",
    "pcd.points = o3.utility.Vector3dVector(pcd_points)\n",
    "\n",
    "# initialize KD tree object\n",
    "pcd_tree = o3.geometry.KDTreeFlann(pcd)\n",
    "\n",
    "# perform search over radius r = 0.2\n",
    "[k, idx, a] = pcd_tree.search_radius_vector_3d(pcd.points[10], 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stuff(predictions, points, cat, npoints=15000, radius=0.2, M=500):\n",
    "    predictions = pred_choice.reshape(-1).to('cpu') # Nx1\n",
    "    pcd_points = norm_points.permute(2, 0, 1).reshape(3, -1).to('cpu').T # Nx3\n",
    "\n",
    "    # downsample points\n",
    "    choice = np.random.choice(len(pcd_points), 15000, replace=False)\n",
    "    pcd_points = pcd_points[choice]\n",
    "    predictions = predictions[choice]\n",
    "\n",
    "    # only obtain points for current category\n",
    "    pcd_points = pcd_points[predictions == cat]\n",
    "\n",
    "    # place them into a point cloud object\n",
    "    pcd = o3.geometry.PointCloud()\n",
    "    pcd.points = o3.utility.Vector3dVector(pcd_points)\n",
    "\n",
    "    # initialize KD tree object\n",
    "    pcd_tree = o3.geometry.KDTreeFlann(pcd)\n",
    "\n",
    "    # perform M proposal searches over radius \n",
    "    p_idxs = np.random.choice(len(pcd_points), M, replace=False)\n",
    "    for p in p_idxs:\n",
    "        [k, idx, _] = pcd_tree.search_radius_vector_3d(pcd.points[p], radius=radius)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.8 (tags/v3.7.8:4b47a5b6ba, Jun 28 2020, 08:53:46) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
